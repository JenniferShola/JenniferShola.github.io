---
title: "Where Did the Time Go? - My One Month Update on the Open AI Scholars Program"
date: 2020-11-10
categories:
  - OpenAIScholars
tags:
  - Open AI Scholars Program
  - Advice
  - Exploration
  - Code First
  - Sprints
---

*This post was written as apart of the Open AI Scholars program. It is Part 2 in the series. Read [Part 1]({% post_url 2020-10-25-learning-how-to-learn %}), [Part 3]({% post_url 2020-11-20-developing-a-research-pov %}). Find [all](/tags/#open-ai-scholars-program) posts relating to the program here.*

It's been 4 weeks since the scholars program started. It feels like we just started and yet so much time has passed. I feel like there is still so much left to learn and yet, I feel like I'm radically different from how I started.

**How I'm Feeling?**

Overwhelmed. Tired. Accomplished.

I haven't properly slept since election day. The seasons have changed and the winter chill came earlier than expected. I'm cold, tired, and anxious from the around the clock news cycle. I'm overwhelmed by the number of things there are to learn in AI. *Am I moving the material fast enough? Am I spending enough time digging into an area vs surveying the major algorithms in each space?* I simultaneously feel behind the mountain of research papers beginning to stack on my desk and yet, I ***know*** my understanding of the field has radically changed.

Before the program, I dabbled into machine learning (even writing a model or two), but dabbling and fully understanding deep learning are two very different things. Although I still have much to learn, I feel more confident in my understanding of AI. I've developed a point of view and know how to learn and incorporate what I don't know, something that is arguably one of the hardest things to do. This week will likely be a wash (thank you politics!) but it's just a small part of what has so far been an amazing experience. Regardless of what happens, I'm proud of myself and of the work I'm accomplishing here.

## What I'm Working On

In an earlier blog [post]({% post_url 2020-10-19-principles-to-learn-by %}), I detailed the principles that would guide my approach to learning (as opposed to setting up a fixed curriculum). Here, I want to give my opinion on what has and hasn't been working.

### Exploration

>I haven't always honored exploration in my academic pursuits so I really want to do that at Open AI. I don't want to rush the process or focus on producing just yet. This time is about learning, exploring different methods and understanding which area of AI is a match for my interests and skill sets.

I've been doing ok on this. So far, I've been spending about 2 weeks on every concept, which has been great for in-depth research and technical understanding of the material. However, it hasn't given me as much breadth as I would like, especially given that I am already half-way into the curriculum portion of the program. Next week, I'm working on language models next week but my plan the week after is to focus on a different topic every day and then go in depth once I have an area that I am specifically interested in.

Although I wish I had more understanding of the sub-fields<sup>**</sup> in AI, I think going in depth on the technical research and implementations allowed me to have a better technical understanding of the field. Now that I'm comfortable expanding my expertise, it makes sense to broaden scope and learn more about the landscape before narrowing in on my specific research area.

<sub><sup>**Metalearning, Interpretability, and Open Endedness are examples of sub-fields in AI.</sup></sub>

### Sprints

>Gentle pressure is good. The sprints cycle is familiar to me and I think establishing a routine would enable me to best make slow, consistent progress towards my research goals. Instead of lofty goals, I am only planning 2 weeks ahead at a time.

Not having a curriculum has been great. Every week I reassess if what I'm working on makes sense, which forces me to stick with the big picture vs getting too into the weeds. I organize around smaller milestones, ideally working to make many small incremental milestones vs hitting one large goal. This has been good at forcing me into a stead jog vs an unsustainable run.

### Code First

>I love to read but coding implementations are often the best way for  me to learn. Taking the Fast AI approach, I'm going to focus on trying to build code first and then use the details (i.e. the academic papers) as references to fill in the gaps of knowledge. The goal is to learn deep learning, test my knowledge and reproduce the research.

I broke this rule when I first started the program. I spent a week researching ResNets and learning all the theory behind it before attempting to implement it. Big mistake! As I sat down to write the code, I had to re-teach myself the theory and spend even more time on the architecture.

Since then, I tend to spend about an hour learning about a new concept before following a code tutorial. This format has been great for helping me move through the material much faster. It also allows the research to build off of my understanding of the application, before going into what will surely be the more complex theory.

## The Open Secret

When you don't work in Artificial Intelligence, the industry feels like a mystery. Even when you work in machine learning, it can often feel intimidating if you don't work at the top tech companies. The thing no one tells you is that **no one** knows how this stuff works.

Machine learning is built on of the backs of statistics. Imagine that a statistician's goal is to find the best-fit line. A machine learning engineer's goal is to use the **same** methods to approximate a function that has the best *likelihood* of predicting our intended outcome. While we understand the statistical theory behind most of the techniques we use, there are still gaps in understanding why many of these techniques work.

*No one knows how or why this stuff works.*

That's the open secret.

We are at the tip of humankind's own understanding of the world and as such, we are in that gray area where the rules are uncertain, and our explanations even more so. It is not expected that you understand everything and even if you did, these conventions would change faster than you could keep up with. Much of the statistical techniques we use in AI were created in the 1800s. We are just now combining these methods with the data and computing power necessary to approach something that resembles human level intelligence.

Artificial Intelligence is not something to feel intimidated about. Whether you're trying to learn it or worrying about how it might affect you, I implore you to have courage. If you don't know what's going on or why things work, good... you're just like everyone else.
